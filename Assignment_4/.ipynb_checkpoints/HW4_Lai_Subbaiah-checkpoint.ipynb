{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">MIS 382: Advanced Predictive Modelling</p>\n",
    "# <p style=\"text-align: center;\">Assignment 4</p>\n",
    "## <p style=\"text-align: center;\">Total points: 60</p>\n",
    "## <p style=\"text-align: center;\">Due: Wednesday, November 8th, submitted via Canvas by 11:59 pm</p>\n",
    "## <p style=\"text-align: center;\">By: Tim Lai (ttl353), Meyappan Subbaiah (ms47296)</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTID for all students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group.  \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Bayesian Classifiers (15 pts)\n",
    "\n",
    "In this problem, you will classify between digits 8 and 9 of the MNIST dataset using Bayesian classifiers (LDA, QDA and Naive Bayes) The code below loads the dataset and all necessary sklearn modules. Look up any module on the scikit-learn website for a full description.\n",
    "\n",
    "1. Train Linear Discriminant Analysis, Quadratic Discriminant Analysis, and (Gaussian) Naive Bayes. Extract the probability of the class being digits 8 or digits 9 for every row. \n",
    "2. Use this to plot the receiver operating characteristic (ROC) curve. (one figure for all 3 models, with a label for each line) \n",
    "3. Report the area under the ROC curve (AUC) for each model. (5 pts for each model. Total of 15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata(\"MNIST original\", data_home='./dataset/')  # data downloaded in'./dataset/', change if necessary\n",
    "\n",
    "X= (mnist.data / 255.)\n",
    "y = mnist.target\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((11800, 784), (11800,), (1983, 784), (1983,))\n"
     ]
    }
   ],
   "source": [
    "idx = (y_train == 8) + (y_train==9)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "y_train = (y_train-8)\n",
    "\n",
    "idx = (y_test == 8) + (y_test==9)\n",
    "X_test = X_test[idx]\n",
    "y_test = y_test[idx]\n",
    "y_test = (y_test-8)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.99740516e-01,   2.59484124e-04],\n",
       "       [  9.99999830e-01,   1.69840181e-07],\n",
       "       [  9.99978789e-01,   2.12106777e-05],\n",
       "       ..., \n",
       "       [  2.82800672e-09,   9.99999997e-01],\n",
       "       [  5.97602137e-08,   9.99999940e-01],\n",
       "       [  1.59061098e-09,   9.99999998e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "lda_probs = lda.predict_proba(X_test)\n",
    "lda_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quadratic Discriminant Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+000,   1.25488809e-296],\n",
       "       [  1.00000000e+000,   0.00000000e+000],\n",
       "       [  1.00000000e+000,   0.00000000e+000],\n",
       "       ..., \n",
       "       [  0.00000000e+000,   1.00000000e+000],\n",
       "       [  0.00000000e+000,   1.00000000e+000],\n",
       "       [  0.00000000e+000,   1.00000000e+000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QDA()\n",
    "qda.fit(X_train, y_train)\n",
    "qda_probs = qda.predict_proba(X_test)\n",
    "qda_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Gaussian) Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+000,   0.00000000e+000],\n",
       "       [  1.00000000e+000,   0.00000000e+000],\n",
       "       [  1.00000000e+000,   0.00000000e+000],\n",
       "       ..., \n",
       "       [  4.29907815e-178,   1.00000000e+000],\n",
       "       [  2.35127896e-114,   1.00000000e+000],\n",
       "       [  1.72617317e-182,   1.00000000e+000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnb_probs = gnb.predict_proba(X_test)\n",
    "gnb_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roc Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmBhLCsYYY2IsKRhjjIn5/6a+p+1ODM5KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ab45d10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda_fpr, lda_tpr, lda_thresholds = roc_curve(y_test, lda_probs[:, 1])\n",
    "qda_fpr, qda_tpr, qda_thresholds = roc_curve(y_test, qda_probs[:, 1])\n",
    "gnb_fpr, gnb_tpr, gnb_thresholds = roc_curve(y_test, gnb_probs[:, 1])\n",
    "plt.plot(lda_fpr, lda_tpr,label='LDA')\n",
    "plt.plot(qda_fpr, qda_tpr,label='QDA')\n",
    "plt.plot(gnb_fpr, gnb_tpr,label='GNB')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for Linear Discriminant Analysis is: 0.994\n",
      "The AUC for Quadratic Discriminant Analysis is: 0.941\n",
      "The AUC for Gaussian Naive Bayes is: 0.902\n"
     ]
    }
   ],
   "source": [
    "print \"The AUC for Linear Discriminant Analysis is: {:.3f}\".format(roc_auc_score(y_test, lda_probs[:, 1]))\n",
    "print \"The AUC for Quadratic Discriminant Analysis is: {:.3f}\".format(roc_auc_score(y_test, qda_probs[:, 1]))\n",
    "print \"The AUC for Gaussian Naive Bayes is: {:.3f}\".format(roc_auc_score(y_test, gnb_probs[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Bayesian Networks (10 pts)\n",
    "In the Bayesian Network shown below, the nodes represent the following random variables: S stands for \"Smoking\", LC for \"Lung Cancer\", B for \"Bronchitis\", T for \"Tuberculosis\", D for \"Dyspnea\". The necessary conditional probabilities are provided alongside. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMIAAAEgCAYAAADmGqwMAAAAAXNSR0IArs4c6QAAAAlwSFlzAAAX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\nbzorJ37m3P8D2+r2TYVhyEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='BayesianNetworks.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Pr(S = yes) = 0.1$$\n",
    "$$Pr(LC = yes | S = yes) = 0.03$$\n",
    "$$Pr(LC = yes | S = no) = 0.01$$\n",
    "$$Pr(B = yes | S = yes) = 0.06$$\n",
    "$$Pr(B = yes | S = no) = 0.02$$\n",
    "$$Pr(T = yes | LC = yes, B = yes) = 0.8$$\n",
    "$$Pr(T = yes | LC = yes, B = no) = 0.5$$\n",
    "$$Pr(T = yes | LC = no, B = yes) = 0.1$$\n",
    "$$Pr(T = yes | LC = no, B = no) = 0.04$$\n",
    "$$Pr(D = yes | T = yes, B = yes) = 0.9$$\n",
    "$$Pr(D = yes | T = yes, B = no) = 0.7$$\n",
    "$$Pr(D = yes | T = no, B = yes) = 0.65$$\n",
    "$$Pr(D = yes | T = no, B = no) = 0.015$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the following probabilities:\n",
    "\n",
    "(a) (2 pts) $Pr(D = yes)$\n",
    "\n",
    "(b) (2 pts) $Pr(LC = no, B = yes, D = yes)$\n",
    "\n",
    "(c) (3 pts) Given that a person has Bronchitis (B = yes) and no Lung Cancer (LC = no), the probability he will has symptoms of Dyspnea (D = yes).\n",
    "\n",
    "(d) (3 pts) Given that a person is a smoker (S = yes), the probability he will get infected with Tuberculosis (T = yes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Develop Conditional Probability Tables for all Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Smoker Node**\n",
    "\n",
    "\n",
    "| T | F |\n",
    "|------|------|\n",
    "|   0.1  | 0.9|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lung Cancer Node **\n",
    "\n",
    "| | LC = T | LC = F |\n",
    "|----- |------|------|\n",
    "| Smoke = T|   0.03  | 0.97|\n",
    "| Smoke = F|   0.01  | 0.99|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Bronchitis Node **\n",
    "\n",
    "| | B = T | B = F |\n",
    "|----- |------|------|\n",
    "| Smoke = T|   0.06  | 0.94|\n",
    "| Smoke = F|   0.02  | 0.98|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Tuberculosis Node**\n",
    "\n",
    "|      |      | T = T | T = F |\n",
    "|------|------|-------|-------|\n",
    "|LC = T| B = T|   0.8  | 0.2|\n",
    "|LC = T| B = F|   0.5  | 0.5|\n",
    "|LC = F| B = T|   0.1  | 0.9|\n",
    "|LC = F| B = F|   0.04 | 0.96|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Dyspnea Node **\n",
    "\n",
    "|      |      | D = T | D = F |\n",
    "|------|------|-------|-------|\n",
    "|Tub = T| B = T|   0.9  | 0.1|\n",
    "|Tub = T| B = F|   0.7  | 0.3|\n",
    "|Tub = F| B = T|   0.65  | 0.35|\n",
    "|Tub = F| B = F|   0.015 | 0.985|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Pr(D=Yes) = (A) + (B) + (C) + (D) $, where:\n",
    "\n",
    "$$ (A) - Pr(D = Y | Tub = T, B = T) * P(Tub=T|B=T) * P(B=T)  $$\n",
    "$$ (B) - Pr(D = Y | Tub = T, B = F) * P(Tub=T|B=F) * P(B=F)  $$\n",
    "$$ (C) - Pr(D = Y | Tub = F, B = T) * P(Tub=F|B=T) * P(B=T)  $$\n",
    "$$ (D) - Pr(D = Y | Tub = F, B = F) * P(Tub=F|B=F) * P(B=F)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we find $P(B = T) * P(B=F)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(B=T) = P(B=T|S=T) * P(S=T) + P(B=T|S=F) * P(S=F) $$\n",
    "Values obtained from the above tables.\n",
    "$$ P(B=T) = (0.06) * (0.1) + (0.02)(0.9) = 0.024 $$\n",
    "$$ P(B=F) = 1-P(B=T) = 1-0.024 = 0.976 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we find $P(Tub \\in (T,F) | B \\in (T,F))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Tub=T|B=T) = P(Tub=T | B=T,LC=T)P(LC=T) + P(Tub=T | B=T,LC=F)P(LC=F) $$\n",
    "$$ P(Tub=T|B=T) = (0.8) * (0.012) + (0.1) * (0.988) = 0.1084 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Tub=T|B=F) = P(Tub=T | B=F,LC=T)P(LC=T) + P(Tub=T | B=F,LC=F)P(LC=F) $$\n",
    "$$ P(Tub=T|B=F) = (0.5)*(0.012) + (0.04) * (0.988) = 0.04552 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Tub=F|B=T) = P(Tub=F | B=T,LC=T)P(LC=T) + P(Tub=F | B=T,LC=F)P(LC=F) $$\n",
    "$$ P(Tub=F|B=T) = (0.2) * (0.012) + (0.9)*(0.988) = 0.8916 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Tub=F|B=F) = P(Tub=F | B=F,LC=T)P(LC=T) + P(Tub=F | B=F,LC=F)P(LC=F) $$\n",
    "$$ P(Tub=F|B=F) = (0.5) * (0.012) + (0.96)*(0.988) = 0.95448$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go back and compute (A), (B), (C), (D), resulting in:\n",
    "\n",
    "(A) = 0.00234144  \n",
    "(B) = 0.031099264  \n",
    "(C) = 0.01390896  \n",
    "(D) = 0.0139735872  \n",
    "**Pr(D=Yes) = (A) + (B) + (C) + (D) = 0.0614 = 6.14%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(D=T,LC=F,B=T) = (1) + (2) $, where \n",
    "\n",
    "$$ (1) - P(D=T,Tub=T,B=T,LC=F) $$\n",
    "$$ (2) - P(D=T,Tub=F,B=T,LC=F) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) = \n",
    "$$ P(D=T,T=T,B=T,LC=F) = P(D=T|Tub=T,B=T)*P(Tub=T|B=T,LC=F)*P(LC=F)*P(B=T) $$ \n",
    "$$ P(D=T,Tub=T,B=T,LC=F) = (0.9) * (0.1) * (0.988) * (0.024) = 0.00213408 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) =\n",
    "$$ P(D=T,Tub=F,B=T,LC=F) = P(D=T|Tub=T,B=T)*P(Tub=T|B=T,LC=F)*P(LC=F)*P(B=T)$$ \n",
    "$$ P(D=T,Tub=F,B=T,LC=F) = (0.65) * (0.9) * (0.988) * (0.024) = 0.01387152 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P(D=T,LC=F,B=T) = 1.60056%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(D=True|B=T,LC=F) = \\dfrac{P(D=Yes,B=T,LC=F)}{P(B=T,LC=F)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found in Part B: P(D=Yes,B=T,LC=F) = 0.0160056"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(B=T,LC=F) = P(B=T,LC=F,S=T) + P(B=T,LC=F,S=F)$$\n",
    "$$ P(B=T,LC=F) = P(B=T|S=T)*P(S=T)*P(LC=F|S=T) + P(B=T|S=F)*P(S=F)*P(LC=F|S=F) $$\n",
    "$$ P(B=T,LC=F) = (0.06) * (0.1) * (0.97) + (0.02)*(0.9)*(0.99) = 0.02364 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(D=True|B=T,LC=F) = \\dfrac{P(D=Yes,B=T,LC=F)}{P(B=T,LC=F)} = \\dfrac{0.0160056}{0.02364} $  \n",
    "**P(D=True|B=T,LC=F) = 67.7%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ P(Tub=True|S=T) = \\dfrac{P(Tub=T,S=T)}{P(S=T)} = \\dfrac{P(Tub=T,S=T)}{0.9} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Tub=T,S=T) = (1) + (2) + (3) + (4) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(1) =  \n",
    "$$ P(Tub = T | B = T,LC=T)P(B=T|S=T)P(LC=T|S=T)P(S=T) =(0.8) * (0.06) * (0.03) * (0.1) = 0.000144 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) =  \n",
    "$$ P(Tub = T | B = F,LC=T)P(B=F|S=T)P(LC=T|S=T)P(S=T) =(0.5) * (0.94) * (0.03) * (0.1) = 0.00141 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) =  \n",
    "$$ P(Tub = T | B = T,LC=F)P(B=T|S=T)P(LC=F|S=T)P(S=T) =(0.1) * (0.06) * (0.97) * (0.1) = 0.000582 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) =  \n",
    "$$ P(Tub = T | B = F,LC=F)P(B=F|S=T)P(LC=F|S=T)P(S=T) =(0.04) * (0.94) * (0.97) * (0.1) = 0.0036472 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(Tub=T,S=T) = 0.0057832 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P(Tub=True|S=T) = 0.006425778 = 0.6425778%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 - Logistic Regression Classification (15pts)\n",
    "\n",
    "Using the MNIST dataset in Q1, the goal is to build a Logistic Regression classifier to classify between digits $\\textbf{8 and 9}$.  Note that the imported MNIST dataset has 10 labels, from digits 0 to 9.  Use the code below to access the data set and extract the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use code from Q1 to import the data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata(\"MNIST original\", data_home='./dataset/')  # data downloaded in'./dataset/', change if necessary\n",
    "\n",
    "X= (mnist.data / 255.)\n",
    "y = mnist.target\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((11800, 784), (11800,), (1983, 784), (1983,))\n"
     ]
    }
   ],
   "source": [
    "idx = (y_train == 8) + (y_train==9)\n",
    "X_train = X_train[idx]\n",
    "y_train = y_train[idx]\n",
    "y_train = (y_train-8)\n",
    "\n",
    "idx = (y_test == 8) + (y_test==9)\n",
    "X_test = X_test[idx]\n",
    "y_test = y_test[idx]\n",
    "y_test = (y_test-8)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train a logistic regression with almost no regularization (pass l2 (ridge) to penalty and 1,000,000 to the C parameter which is the inverse of regularization strength lambda. This essentially does l2 regularization but applies very little weight to the penalty term) and report the [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) on the test data. Also report the accuracy for the \"y = 0\" class, the \"y = 1\" class, and the average per-class accuracy on the test data. Average per-class accuracy is described in this [post](http://rasbt.github.io/mlxtend/user_guide/evaluate/scoring/). You can use your confusion matrix to calculate this.  (4pts)\n",
    "2. Repeat step 1 except use l2 penalty with Cs of [0.01, 0.1, 1, 10 ,100]. You will want to use 3-fold cross validation to select the best parameter. To evaluate which parameter is best, maximize the average per-class accuracy. To help with this task, check out [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) and how to make your own [custom scorer](http://scikit-learn.org/stable/modules/model_evaluation.html).  (4pts)\n",
    "3. Repeat question 2 except use l1 instead of l2 as the penalty type, use Cs of  [0.01, ..., 100].  Compare the performances of the models (no regularization, l2, l1) using the average per-class accuracy.  (3pts)\n",
    "4. Using the optimal regularization parameter obtained in step 2, train a logistic regression classifier with ridge penalty to clasify $\\textbf{all 10 digits}$ (digits 0,1,2,3,...9) of the MNIST dataset.  Use 'newton-cg' and 'multinomial' options for solver and multi_class parameters, respectively. Report the average per-class accuracy and confusion matrix (10 X 10) on the test data. (4pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "l2_LR = LogisticRegression(C=1000000,penalty='l2')\n",
    "l2_LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Report Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[940,  34],\n",
       "       [ 35, 974]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = l2_LR.predict(X_test)\n",
    "l2_conf_mat = confusion_matrix(y_test,y_pred)\n",
    "l2_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_0_acc = l2_conf_mat[0,0]/float(sum(l2_conf_mat[0,]))\n",
    "y_1_acc = l2_conf_mat[1,1]/float(sum(l2_conf_mat[1,]))\n",
    "acc = np.sum(np.diagonal(l2_conf_mat))/float(np.sum(l2_conf_mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the y=0 class is: 0.965\n",
      "Accuracy for the y=1 class is: 0.965\n",
      "Average per-class accuracy is: 0.965\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy for the y=0 class is: {:.3f}\".format(y_0_acc)\n",
    "print \"Accuracy for the y=1 class is: {:.3f}\".format(y_1_acc)\n",
    "print \"Average per-class accuracy is: {:.3f}\".format(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "def acc_per_class(ground_truth, predictions):\n",
    "    conf_mat = confusion_matrix(ground_truth,predictions)\n",
    "    acc = np.sum(np.diagonal(conf_mat))/float(np.sum(conf_mat))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1000000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring=make_scorer(acc_per_class), verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "acc_class_score = make_scorer(acc_per_class, greater_is_better=True)\n",
    "c_param = {'C':[0.01,0.1, 1, 10 ,100]}\n",
    "grid_l2 = GridSearchCV(l2_LR, c_param, cv = 3, scoring= acc_class_score)\n",
    "grid_l2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "The maximum average per-class accuracy is: 0.983\n"
     ]
    }
   ],
   "source": [
    "print grid_l2.best_params_\n",
    "print \"The maximum average per-class accuracy is: {:.3f}\".format(grid_l2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1000000, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1, 10, 100]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, scoring=make_scorer(acc_per_class), verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_LR = LogisticRegression(C=1000000,penalty='l1')\n",
    "grid_l1 = GridSearchCV(l1_LR, c_param, cv = 3, scoring= acc_class_score)\n",
    "grid_l1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "The maximum average per-class accuracy is: 0.981\n"
     ]
    }
   ],
   "source": [
    "print grid_l1.best_params_\n",
    "print \"The maximum average per-class accuracy is: {:.3f}\".format(grid_l1.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Model Performance **\n",
    "\n",
    "Model performance was measured using the average per-class accuracy. \n",
    "\n",
    "With No Regularization, we obtained a value of **0.965**.  \n",
    "L2 Regularization, we obtained a value of **0.983**.  \n",
    "L1 Regularization, we obtained a value of **0.981**.  \n",
    "\n",
    "Based on additional research, L1 regularization is, in theory, the more effective choice in performing feature selection in sparse feature spaces. Since L1 allows for feature growth logarithmically vs. L2 which allows the same linearly, L1 can be expected to be more flexible and eliminates unnecessary attributes similar to lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= (mnist.data / 255.)\n",
    "y = mnist.target\n",
    "\n",
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimal_LR = LogisticRegression(C=1,penalty='l2',solver='newton-cg',multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_LR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = optimal_LR.predict(X_test)\n",
    "optimal_conf_mat = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average per-class accuracy is: 0.926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 955,    0,    2,    4,    1,   10,    4,    3,    1,    0],\n",
       "       [   0, 1110,    5,    2,    0,    2,    3,    2,   11,    0],\n",
       "       [   6,    9,  930,   14,   10,    3,   12,   10,   34,    4],\n",
       "       [   4,    1,   16,  925,    1,   23,    2,   10,   19,    9],\n",
       "       [   1,    3,    7,    3,  921,    0,    6,    5,    6,   30],\n",
       "       [   9,    2,    3,   35,   10,  777,   15,    6,   31,    4],\n",
       "       [   8,    3,    8,    2,    6,   16,  912,    2,    1,    0],\n",
       "       [   1,    7,   23,    7,    6,    1,    0,  947,    4,   32],\n",
       "       [   9,   11,    6,   22,    7,   29,   13,   10,  855,   12],\n",
       "       [   9,    8,    1,    9,   21,    7,    0,   21,    9,  924]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"The average per-class accuracy is: {:.3f}\".format(acc_per_class(y_test,y_pred))\n",
    "optimal_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Regression Trees (6+5+4 = 15 points)\n",
    "In this question, we will be exploring the application of regression tree (RT) using sklearn package in Python. \n",
    "\n",
    "You will be using an NBA dataset (nbasalariesfull.csv) to predict a player’s Salary (in terms of millions, ie Salary / 1000000 ) using all the numeric performance variables available ( so everything but Player, Team, and Position ). \n",
    "\n",
    "- a. Use a random state of 42 and a test size of 1/3 to split the data into training and test.\n",
    "     \n",
    "         Build a regression using DecisionTreeRegressor with max_depth = 6. \n",
    "         Report the mean squared errors on both training and test datasets.( 6 points )\n",
    "\n",
    "\n",
    "- b. Repeat Part-1 with max_depth = 2. (5 points )\n",
    "\n",
    "\n",
    "- c. Briefly explain what you observe from these MSE values obtained by using maximum tree depths 6 and 2? \n",
    "         Which tree is better and why? ( 4 points )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we import the csv and split into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG%</th>\n",
       "      <th>...</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PSG</th>\n",
       "      <th>SALARY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>PG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>0.504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>11370786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>HOU</td>\n",
       "      <td>SG</td>\n",
       "      <td>26.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>19.7</td>\n",
       "      <td>0.439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15756438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>OKC</td>\n",
       "      <td>SF</td>\n",
       "      <td>27.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>28.2</td>\n",
       "      <td>20158622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>SAC</td>\n",
       "      <td>C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.451</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>11.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>26.9</td>\n",
       "      <td>15851950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>CLE</td>\n",
       "      <td>SF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>9.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>25.3</td>\n",
       "      <td>22970500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Player   Tm Pos   Age     G    GS    MP    FG   FGA    FG%  \\\n",
       "0     Stephen Curry  GSW  PG  27.0  79.0  79.0  34.2  10.2  20.2  0.504   \n",
       "1      James Harden  HOU  SG  26.0  82.0  82.0  38.1   8.7  19.7  0.439   \n",
       "2      Kevin Durant  OKC  SF  27.0  72.0  72.0  35.8   9.7  19.2  0.505   \n",
       "3  DeMarcus Cousins  SAC   C  25.0  65.0  65.0  34.6   9.2  20.5  0.451   \n",
       "4      LeBron James  CLE  SF  31.0  76.0  76.0  35.6   9.7  18.6  0.520   \n",
       "\n",
       "     ...     ORB  DRB   TRB  AST  STL  BLK  TOV   PF   PSG    SALARY  \n",
       "0    ...     0.9  4.6   5.4  6.7  2.1  0.2  3.3  2.0  30.1  11370786  \n",
       "1    ...     0.8  5.3   6.1  7.5  1.7  0.6  4.6  2.8  29.0  15756438  \n",
       "2    ...     0.6  7.6   8.2  5.0  1.0  1.2  3.5  1.9  28.2  20158622  \n",
       "3    ...     2.4  9.1  11.5  3.3  1.6  1.4  3.8  3.6  26.9  15851950  \n",
       "4    ...     1.5  6.0   7.4  6.8  1.4  0.6  3.3  1.9  25.3  22970500  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbasalaries = pd.read_csv('nbasalariesfull.csv')\n",
    "nbasalaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = nbasalaries.drop(['Player','Tm','Pos', 'SALARY'], axis=1)\n",
    "y = nbasalaries['SALARY']/1e6\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a regression with max depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting the model with train data\n",
    "salaries6 = DecisionTreeRegressor(max_depth=6)\n",
    "salaries6_fit = salaries6.fit(X_train, y_train)\n",
    "\n",
    "# Predicting salaries with test data\n",
    "salaries6_train_pred = salaries6_fit.predict(X_train)\n",
    "salaries6_pred = salaries6_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train) Mean squared error is: 3.11\n",
      "(Test) Mean squared error: 18.84\n"
     ]
    }
   ],
   "source": [
    "train_mse = mean_squared_error(y_train,salaries6_train_pred)\n",
    "test_mse = mean_squared_error(y_test, salaries6_pred)\n",
    "print \"(Train) Mean squared error is: %.2f\" % train_mse\n",
    "print \"(Test) Mean squared error: %.2f\" % test_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b) - Same as above but now with max depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting the model with train data\n",
    "salaries2 = DecisionTreeRegressor(max_depth=2)\n",
    "salaries2_fit = salaries2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting salaries with test data\n",
    "salaries2_train_pred = salaries2_fit.predict(X_train)\n",
    "salaries2_pred = salaries2_fit.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reporting MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Train) Mean squared error is: 12.14\n",
      "(Test) Mean squared error: 16.86\n"
     ]
    }
   ],
   "source": [
    "train2_mse = mean_squared_error(y_train,salaries2_train_pred)\n",
    "test2_mse = mean_squared_error(y_test, salaries2_pred)\n",
    "print \"(Train) Mean squared error is: %.2f\" % train2_mse\n",
    "print \"(Test) Mean squared error: %.2f\" % test2_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (c) Explaining the two models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looking at both of our tree models, the model with a max depth of 6 at first glance performs slightly better in terms of MSE; however, when we further look into test MSE, we see that the model with max depth 6 overfits the model to fit the test data, and therefore has a much higher MSE in that regard.\n",
    "\n",
    "Ultimately, to more accurately build a salary prediction model, we should consider additional depths and other parameters such as number of trees in order to lose some bias that caused the overfitting here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5.  AUC vs Lift Curve ( 5 points )\n",
    "Describe the similarities and differences between AUC and Lift Curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formally, both AUC and lift curves help us to identify the model quality of simple models.\n",
    "\n",
    "AUC represents Area Under Curve, or the total area under a generated ROC curve which depicts the true positives vs. false positives. The closer the total area reaches 1, the better quality the model.\n",
    "\n",
    "On the other hand, the Lift curve is slightly different as it does not relate to the ROC curve. The lift curve measures results as a ratio of results obtained with the model compared to random guess. The Lift curve can be considered a better metric for quality in terms of data mining. \n",
    "\n",
    "The ROC curve provides the ability to identify as many true positives as possible in the model, as opposed to overfitting to find all positives. The lift curve just evaluates the performance of the model in comparision to guessing randomly. One refines the model based on a threshold and the other provides model performance details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
